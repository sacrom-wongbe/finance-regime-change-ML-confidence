{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7023ddf5",
   "metadata": {},
   "source": [
    "# Aggregate Data into Weekly Averages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "288e6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def process_weekly_averages(data_path, output_path, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Process stock data into weekly averages based on 7-day increments using Close price.\n",
    "\n",
    "    Parameters:\n",
    "    - data_path: Path to the input CSV file\n",
    "    - output_path: Path for the output CSV file\n",
    "    - start_date: Start date string (format: 'YYYY-MM-DD')\n",
    "    - end_date: End date string (format: 'YYYY-MM-DD')\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    # Ensure the first column is treated as Date, regardless of its header\n",
    "    cols = list(df.columns)\n",
    "    if len(cols) == 0:\n",
    "        raise ValueError(\"Input file has no columns\")\n",
    "    cols[0] = 'Date'\n",
    "    df.columns = cols\n",
    "\n",
    "    # Find a Close-like column\n",
    "    def find_close_column(columns):\n",
    "        def norm(c):\n",
    "            return c.strip().lower()\n",
    "        # 1) exact 'close'\n",
    "        for c in columns:\n",
    "            if norm(c) == 'close':\n",
    "                return c\n",
    "        # 2) common variants\n",
    "        variants = {\n",
    "            'adj close', 'adj_close', 'closing price', 'close price', 'price close'\n",
    "        }\n",
    "        for c in columns:\n",
    "            if norm(c) in variants:\n",
    "                return c\n",
    "        # 3) contains 'close'\n",
    "        for c in columns:\n",
    "            if 'close' in norm(c):\n",
    "                return c\n",
    "        return None\n",
    "\n",
    "    close_col = find_close_column(df.columns)\n",
    "    if close_col is None:\n",
    "        raise ValueError(\"Couldn't find a 'Close' column in the file. Ensure a column named 'Close' exists.\")\n",
    "\n",
    "    # Keep only Date and Close, normalize column name\n",
    "    df = df[['Date', close_col]].rename(columns={close_col: 'Close'})\n",
    "\n",
    "    # Parse dates and Close values\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df['Close'] = pd.to_numeric(df['Close'], errors='coerce')\n",
    "    df = df.dropna(subset=['Date', 'Close'])\n",
    "\n",
    "    # Filter data between start and end dates\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end = pd.to_datetime(end_date)\n",
    "    df = df[(df['Date'] >= start) & (df['Date'] <= end)]\n",
    "\n",
    "    # Sort by date\n",
    "    df = df.sort_values('Date')\n",
    "\n",
    "    # Create week bins based on 7-day increments from start date\n",
    "    df['Days_From_Start'] = (df['Date'] - start).dt.days\n",
    "    df['Week_Number'] = df['Days_From_Start'] // 7\n",
    "\n",
    "    # Calculate the week start/end dates for each entry\n",
    "    df['Week_Start'] = start + pd.to_timedelta(df['Week_Number'] * 7, unit='D')\n",
    "    df['Week_End'] = df['Week_Start'] + pd.Timedelta(days=6)\n",
    "\n",
    "    # Group by week and calculate average close price\n",
    "    weekly_avg = (\n",
    "        df.groupby(['Week_Number', 'Week_Start', 'Week_End'])\n",
    "          .agg({'Close': 'mean', 'Date': 'count'})\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    # Rename columns\n",
    "    weekly_avg.columns = ['Week_Number', 'Week_Start', 'Week_End', 'Avg_Close_Price', 'Trading_Days']\n",
    "\n",
    "    # Format dates\n",
    "    weekly_avg['Week_Start'] = weekly_avg['Week_Start'].dt.strftime('%Y-%m-%d')\n",
    "    weekly_avg['Week_End'] = weekly_avg['Week_End'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Save to CSV\n",
    "    weekly_avg.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Processed {len(df)} daily records into {len(weekly_avg)} weekly averages\")\n",
    "    print(f\"Output saved to: {output_path}\")\n",
    "\n",
    "    return weekly_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9e0dd0",
   "metadata": {},
   "source": [
    "# Aggregate SPX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "845775cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5035 daily records into 1044 weekly averages\n",
      "Output saved to: data/SPX_weekly_averages.csv\n",
      "\n",
      "SPX — First 10 weeks:\n",
      "   Week_Number  Week_Start    Week_End  Avg_Close_Price  Trading_Days\n",
      "0            0  1998-09-28  1998-10-04      1020.741992             5\n",
      "1            1  1998-10-05  1998-10-11       977.532007             5\n",
      "2            2  1998-10-12  1998-10-18      1020.390015             5\n",
      "3            3  1998-10-19  1998-10-25      1069.078027             5\n",
      "4            4  1998-10-26  1998-11-01      1078.069995             5\n",
      "5            5  1998-11-02  1998-11-08      1123.193994             5\n",
      "6            6  1998-11-09  1998-11-15      1124.567969             5\n",
      "7            7  1998-11-16  1998-11-22      1147.165991             5\n",
      "8            8  1998-11-23  1998-11-29      1187.599976             4\n",
      "9            9  1998-11-30  1998-12-06      1167.408008             5\n",
      "\n",
      "SPX — Last 10 weeks:\n",
      "      Week_Number  Week_Start    Week_End  Avg_Close_Price  Trading_Days\n",
      "1034         1034  2018-07-23  2018-07-29      2825.941992             5\n",
      "1035         1035  2018-07-30  2018-08-05      2819.964063             5\n",
      "1036         1036  2018-08-06  2018-08-12      2850.681982             5\n",
      "1037         1037  2018-08-13  2018-08-19      2834.215967             5\n",
      "1038         1038  2018-08-20  2018-08-26      2862.700000             5\n",
      "1039         1039  2018-08-27  2018-09-02      2902.189990             5\n",
      "1040         1040  2018-09-03  2018-09-09      2883.762512             4\n",
      "1041         1041  2018-09-10  2018-09-16      2892.619922             5\n",
      "1042         1042  2018-09-17  2018-09-23      2912.295996             5\n",
      "1043         1043  2018-09-24  2018-09-30      2913.776025             5\n"
     ]
    }
   ],
   "source": [
    "# Process SPX data from Monday Sept 28, 1998 to Sunday Sept 30, 2018\n",
    "result_spx = process_weekly_averages(\n",
    "    data_path='data/SPX.csv',\n",
    "    output_path='data/SPX_weekly_averages.csv',\n",
    "    start_date='1998-09-28',\n",
    "    end_date='2018-09-30'\n",
    ")\n",
    "\n",
    "# Display examples\n",
    "print(\"\\nSPX — First 10 weeks:\")\n",
    "print(result_spx.head(10))\n",
    "print(\"\\nSPX — Last 10 weeks:\")\n",
    "print(result_spx.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeb7c65",
   "metadata": {},
   "source": [
    "# Aggregate KOSPI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ba54e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4927 daily records into 1044 weekly averages\n",
      "Output saved to: data/KOSPI_weekly_averages.csv\n",
      "\n",
      "First 10 weeks:\n",
      "   Week_Number  Week_Start    Week_End  Avg_Close_Price  Trading_Days\n",
      "0            0  1987-11-03  1987-11-09       498.096000             5\n",
      "1            1  1987-11-10  1987-11-16       473.162000             5\n",
      "2            2  1987-11-17  1987-11-23       472.278000             5\n",
      "3            3  1987-11-24  1987-11-30       463.972000             5\n",
      "4            4  1987-12-01  1987-12-07       486.998000             5\n",
      "5            5  1987-12-08  1987-12-14       471.578000             5\n",
      "6            6  1987-12-15  1987-12-21       485.574000             5\n",
      "7            7  1987-12-22  1987-12-28       509.923333             3\n",
      "8            8  1987-12-29  1988-01-04       532.040000             1\n",
      "9            9  1988-01-05  1988-01-11       541.380000             5\n",
      "\n",
      "Last 10 weeks:\n",
      "      Week_Number  Week_Start    Week_End  Avg_Close_Price  Trading_Days\n",
      "1034         1035  2007-09-04  2007-09-10      1869.982000             5\n",
      "1035         1036  2007-09-11  2007-09-17      1850.120000             5\n",
      "1036         1037  2007-09-18  2007-09-24      1892.372500             4\n",
      "1037         1038  2007-09-25  2007-10-01      1951.476667             3\n",
      "1038         1039  2007-10-02  2007-10-08      2006.635000             4\n",
      "1039         1040  2007-10-09  2007-10-15      2035.186000             5\n",
      "1040         1041  2007-10-16  2007-10-22      1973.740000             5\n",
      "1041         1042  2007-10-23  2007-10-29      1989.814000             5\n",
      "1042         1043  2007-10-30  2007-11-05      2043.092000             5\n",
      "1043         1044  2007-11-06  2007-11-12      2048.715000             2\n"
     ]
    }
   ],
   "source": [
    "# Process KOSPI data from Monday Nov 3, 1997 to Wednesday Nov 7, 2007\n",
    "result = process_weekly_averages(\n",
    "    data_path='data/KOSPI.csv',\n",
    "    output_path='data/KOSPI_weekly_averages.csv',\n",
    "    start_date='1987-11-03',\n",
    "    end_date='2007-11-07'\n",
    ")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 10 weeks:\")\n",
    "print(result.head(10))\n",
    "print(\"\\nLast 10 weeks:\")\n",
    "print(result.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81366133",
   "metadata": {},
   "source": [
    "# Aggregate NIKKEI225\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f61fb7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5018 daily records into 1044 weekly averages\n",
      "Output saved to: data/NIKKEI225_weekly_averages.csv\n",
      "\n",
      "First 10 weeks:\n",
      "   Week_Number  Week_Start    Week_End  Avg_Close_Price  Trading_Days\n",
      "0            0  1979-12-24  1979-12-30        6539.7680             5\n",
      "1            1  1979-12-31  1980-01-06        6560.1600             1\n",
      "2            2  1980-01-07  1980-01-13        6583.4560             5\n",
      "3            3  1980-01-14  1980-01-20        6654.6025             4\n",
      "4            4  1980-01-21  1980-01-27        6711.9380             5\n",
      "5            5  1980-01-28  1980-02-03        6771.3680             5\n",
      "6            6  1980-02-04  1980-02-10        6794.2620             5\n",
      "7            7  1980-02-11  1980-02-17        6832.9025             4\n",
      "8            8  1980-02-18  1980-02-24        6777.0860             5\n",
      "9            9  1980-02-25  1980-03-02        6755.3880             5\n",
      "\n",
      "Last 10 weeks:\n",
      "      Week_Number  Week_Start    Week_End  Avg_Close_Price  Trading_Days\n",
      "1034         1035  1999-10-25  1999-10-31       17611.7460             5\n",
      "1035         1036  1999-11-01  1999-11-07       18172.9775             4\n",
      "1036         1037  1999-11-08  1999-11-14       18337.3680             5\n",
      "1037         1038  1999-11-15  1999-11-21       18346.3400             5\n",
      "1038         1039  1999-11-22  1999-11-28       18838.6525             4\n",
      "1039         1040  1999-11-29  1999-12-05       18557.4000             5\n",
      "1040         1041  1999-12-06  1999-12-12       18406.9860             5\n",
      "1041         1042  1999-12-13  1999-12-19       18143.0840             5\n",
      "1042         1043  1999-12-20  1999-12-26       18325.6875             4\n",
      "1043         1044  1999-12-27  2000-01-02       18768.8350             4\n"
     ]
    }
   ],
   "source": [
    "# Process NIKKEI225 data from Monday Nov 3, 1979 to Wednesday Nov 7, 1999\n",
    "result = process_weekly_averages(\n",
    "    data_path='data/NIKKEI225.csv',\n",
    "    output_path='data/NIKKEI225_weekly_averages.csv',\n",
    "    start_date='1979-12-24',\n",
    "    end_date='1999-12-31'\n",
    ")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 10 weeks:\")\n",
    "print(result.head(10))\n",
    "print(\"\\nLast 10 weeks:\")\n",
    "print(result.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61760e31",
   "metadata": {},
   "source": [
    "# CPI for Inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5118ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cpi\n",
      "  Downloading cpi-2.0.9-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from cpi) (2.32.5)\n",
      "Requirement already satisfied: click in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from cpi) (8.3.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from cpi) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from cpi) (2.3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from click->cpi) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from pandas->cpi) (2.2.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from pandas->cpi) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from pandas->cpi) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil->cpi) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from requests->cpi) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from requests->cpi) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from requests->cpi) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from requests->cpi) (2025.10.5)\n",
      "Downloading cpi-2.0.9-py2.py3-none-any.whl (18.1 MB)\n",
      "   ---------------------------------------- 0.0/18.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/18.1 MB 8.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 3.4/18.1 MB 9.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 6.0/18.1 MB 10.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 9.2/18.1 MB 11.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 12.1/18.1 MB 12.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 14.9/18.1 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  17.8/18.1 MB 12.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.1/18.1 MB 12.3 MB/s  0:00:01\n",
      "Installing collected packages: cpi\n",
      "Successfully installed cpi-2.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install cpi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1df54b6",
   "metadata": {},
   "source": [
    "# Calculate Adjusted for Inflation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d362ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cpi\n",
    "\n",
    "def adjust_to_cpi_2025(csv_path, current_year, output_path=None):\n",
    "    \"\"\"\n",
    "    Adjust Avg_Close_Price to current year dollars using CPI index.\n",
    "    Uses the year from Week_End as the baseline year for each row.\n",
    "    Appends 'Avg_Close_Price_current_year' column and saves the updated CSV.\n",
    "    \n",
    "    Parameters:\n",
    "    - csv_path: Path to the input CSV file with Avg_Close_Price column\n",
    "    - output_path: Path for the output CSV file (defaults to overwriting input)\n",
    "    \"\"\"\n",
    "    if output_path is None:\n",
    "        output_path = csv_path\n",
    "    \n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    if 'Avg_Close_Price' not in df.columns:\n",
    "        raise ValueError(\"CSV must contain 'Avg_Close_Price' column\")\n",
    "    if 'Week_End' not in df.columns:\n",
    "        raise ValueError(\"CSV must contain 'Week_End' column\")\n",
    "    \n",
    "    # Extract year from Week_End\n",
    "    df['Year'] = pd.to_datetime(df['Week_End']).dt.year\n",
    "    \n",
    "    # Adjust each price to 2025 dollars\n",
    "    adjusted_prices = []\n",
    "    for idx, row in df.iterrows():\n",
    "        original_price = row['Avg_Close_Price']\n",
    "        year = row['Year']\n",
    "        \n",
    "        try:\n",
    "            # Convert from year-dollars to 2025-dollars\n",
    "            adjusted = cpi.inflate(original_price, year, to=current_year)\n",
    "            adjusted_prices.append(adjusted)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not adjust price for year {year}: {e}\")\n",
    "            adjusted_prices.append(None)\n",
    "    \n",
    "    df[f'Avg_Close_Price_{current_year}'] = adjusted_prices\n",
    "    \n",
    "    # Remove temporary Year column\n",
    "    df = df.drop(columns=['Year'])\n",
    "    \n",
    "    # Save the updated CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"CPI-adjusted data saved to: {output_path}\")\n",
    "    print(f\"New column 'Avg_Close_Price_2025' appended with {len([p for p in adjusted_prices if p is not None])} valid adjustments\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca360b4b",
   "metadata": {},
   "source": [
    "# Set Year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b311921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_year = 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f549f118",
   "metadata": {},
   "source": [
    "# Adjust for Inflation SPX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f1b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting SPX weekly averages to 2024 dollars...\n",
      "CPI-adjusted data saved to: data/SPX_weekly_averages.csv\n",
      "New column 'Avg_Close_Price_2025' appended with 1044 valid adjustments\n",
      "\n",
      "SPX sample (first 5 rows):\n",
      "   Week_Start    Week_End  Avg_Close_Price  Avg_Close_Price_2025\n",
      "0  1998-09-28  1998-10-04      1020.741992           1964.389784\n",
      "1  1998-10-05  1998-10-11       977.532007           1881.233360\n",
      "2  1998-10-12  1998-10-18      1020.390015           1963.712413\n",
      "3  1998-10-19  1998-10-25      1069.078027           2057.411149\n",
      "4  1998-10-26  1998-11-01      1078.069995           2074.715943\n"
     ]
    }
   ],
   "source": [
    "# Apply CPI adjustment to SPX weekly averages\n",
    "print(f\"Adjusting SPX weekly averages to {current_year} dollars...\")\n",
    "output_path = 'data/SPX_weekly_averages.csv'\n",
    "spx_adjusted = adjust_to_cpi_2025(output_path, current_year)\n",
    "spx_adjusted.to_csv(output_path, index=False)\n",
    "# Display sample with original and adjusted prices\n",
    "print(\"\\nSPX sample (first 5 rows):\")\n",
    "print(spx_adjusted[['Week_Start', 'Week_End', 'Avg_Close_Price', f'Avg_Close_Price_{current_year}']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048e2a37",
   "metadata": {},
   "source": [
    "# Adjust for Inflation KOSPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a70379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting KOSPI weekly averages to 2024 dollars...\n"
     ]
    }
   ],
   "source": [
    "# Apply CPI adjustment to KOSPI weekly averages\n",
    "print(f\"Adjusting KOSPI weekly averages to {current_year} dollars...\")\n",
    "output_path = 'data/KOSPI_weekly_averages.csv'\n",
    "kospi_adjusted = adjust_to_cpi_2025(output_path, current_year)\n",
    "kospi_adjusted.to_csv(output_path, index=False)\n",
    "# Display sample with original and adjusted prices\n",
    "print(\"\\nKOSPI sample (first 5 rows):\")\n",
    "print(kospi_adjusted[['Week_Start', 'Week_End', 'Avg_Close_Price', f'Avg_Close_Price_{current_year}']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2de2b655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1044"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spx_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea77088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_weeks(csv_path, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Given a weekly CSV and a date range, list missing 7-day bins based on Week_Number.\n",
    "    Assumes columns: Week_Number, Week_Start, Week_End.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    required = ['Week_Number', 'Week_Start', 'Week_End']\n",
    "    for col in required:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing required column '{col}' in {csv_path}\")\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end = pd.to_datetime(end_date)\n",
    "    total_weeks = int(np.floor((end - start).days / 7)) + 1\n",
    "    expected = set(range(total_weeks))\n",
    "    present = set(df['Week_Number'].dropna().astype(int))\n",
    "    missing_numbers = sorted(expected - present)\n",
    "    if missing_numbers:\n",
    "        week_starts = [start + pd.Timedelta(days=7*n) for n in missing_numbers]\n",
    "        week_ends = [ws + pd.Timedelta(days=6) for ws in week_starts]\n",
    "        missing_df = pd.DataFrame({\n",
    "            'Week_Number': missing_numbers,\n",
    "            'Week_Start': [ws.strftime('%Y-%m-%d') for ws in week_starts],\n",
    "            'Week_End': [we.strftime('%Y-%m-%d') for we in week_ends],\n",
    "        })\n",
    "    else:\n",
    "        missing_df = pd.DataFrame(columns=['Week_Number', 'Week_Start', 'Week_End'])\n",
    "    print(f\"Missing weeks: {len(missing_df)} out of {total_weeks} total bins\")\n",
    "    if len(missing_df):\n",
    "        print(missing_df.head(10))\n",
    "    return missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8dc06f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Example: check SPX weekly CSV\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m missing_df = \u001b[43mfind_missing_weeks\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/KOSPI_weekly_averages.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m1987-11-03\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2007-11-07\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mfind_missing_weeks\u001b[39m\u001b[34m(csv_path, start_date, end_date)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_missing_weeks\u001b[39m(csv_path, start_date, end_date):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Given a weekly CSV and a date range, list missing 7-day bins based on Week_Number.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    Assumes columns: Week_Number, Week_Start, Week_End.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     df = \u001b[43mpd\u001b[49m.read_csv(csv_path)\n\u001b[32m      7\u001b[39m     required = [\u001b[33m'\u001b[39m\u001b[33mWeek_Number\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mWeek_Start\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mWeek_End\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m required:\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example: check SPX weekly CSV\n",
    "missing_df = find_missing_weeks('data/KOSPI_weekly_averages.csv', '1987-11-03', '2007-11-07')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7b4db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
